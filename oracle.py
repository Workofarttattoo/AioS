"""
Probabilistic forecasting and quantum simulation utilities for AgentaOS.

The Oracle module keeps all computation in-memory so the operating system can
operate in forensic/immutable environments without mutating host state.  The
implementations favour transparent, explainable scoring over heavyweight
dependencies so the runtime remains portable.
"""

from __future__ import annotations

import math
import random
import statistics
from dataclasses import dataclass
from typing import Dict, Iterable, List, Optional, Any

import torch
import numpy as np

from .ml_algorithms import PatchingTimeSeriesTransformer
from .quantum_ml_algorithms import HybridQuantumMCMC

MAX_QUBITS = 15


@dataclass
class ForecastResult:
    probability: float
    summary: str
    signals: Dict[str, float]
    guidance: List[str]


@dataclass
class QuantumResult:
    qubits: int
    measurements: Dict[str, float]
    entropy: float
    narrative: str


class ProbabilisticOracle:
    """
    Lightweight probabilistic reasoning engine.

    The oracle ingests telemetry stored on the ExecutionContext and emits
    forecast probabilities, risk heatmaps, and quantum-inspired projections.
    It now uses machine learning models for forecasting and inference.
    """

    def __init__(self, forensic_mode: bool = False):
        self.forensic_mode = forensic_mode
        self.forecasting_model = None
        self.model_is_trained = False

    def train(self, historical_telemetry: List[Dict[str, dict]], seq_len: int, pred_len: int) -> Dict[str, Any]:
        """
        Train a forecasting model on historical telemetry data.

        Args:
            historical_telemetry: A list of past telemetry snapshots.
            seq_len: The length of the input sequence for the model.
            pred_len: The length of the future sequence to predict.

        Returns:
            A dictionary containing training status and loss.
        """
        print("[Oracle] Starting model training...")
        if len(historical_telemetry) < seq_len + pred_len:
            return {"status": "error", "message": "Not enough historical data to train."}

        # For this example, we'll train to predict the 'load' signal.
        # 1. Preprocess data into sequences
        sequences = []
        targets = []
        for i in range(len(historical_telemetry) - seq_len - pred_len):
            input_slice = historical_telemetry[i : i + seq_len]
            target_slice = historical_telemetry[i + seq_len : i + seq_len + pred_len]
            
            # Extract load signal for this example
            sequences.append([self._extract_load_signal(t) for t in input_slice])
            targets.append([self._extract_load_signal(t) for t in target_slice])

        X = torch.tensor(sequences, dtype=torch.float32)
        y = torch.tensor(targets, dtype=torch.float32)

        # 2. Initialize and train the PatchingTimeSeriesTransformer
        self.forecasting_model = PatchingTimeSeriesTransformer(
            seq_len=seq_len,
            patch_len=8,  # Hyperparameter, should be tuned
            pred_len=pred_len,
            d_model=64,
            n_heads=8,
            d_ff=128,
            num_layers=3
        )
        
        optimizer = torch.optim.Adam(self.forecasting_model.parameters(), lr=0.001)
        loss_fn = torch.nn.MSELoss()

        # Simplified training loop
        for epoch in range(10): # In a real scenario, more epochs are needed
            optimizer.zero_grad()
            predictions = self.forecasting_model(X)
            loss = loss_fn(predictions, y)
            loss.backward()
            optimizer.step()
        
        self.model_is_trained = True
        print(f"[Oracle] Model training complete. Final loss: {loss.item()}")
        return {"status": "success", "final_loss": loss.item()}

    def predict(self, current_telemetry_sequence: List[Dict[str, dict]]) -> ForecastResult:
        """
        Generate a forecast using the trained model.

        Args:
            current_telemetry_sequence: A sequence of recent telemetry snapshots.

        Returns:
            A ForecastResult with the model's prediction.
        """
        if not self.model_is_trained or self.forecasting_model is None:
            return ForecastResult(0.5, "Model not trained. Please train the oracle first.", {}, ["Train model to enable prediction."])

        # Extract load signal from the input sequence
        input_sequence = [self._extract_load_signal(t) for t in current_telemetry_sequence]
        X = torch.tensor([input_sequence], dtype=torch.float32)

        with torch.no_grad():
            prediction = self.forecasting_model(X).squeeze(0).cpu().numpy()

        # The model predicts future load. We can use the mean of the prediction
        # as the new "probability" of high load.
        probability = float(np.mean(prediction))
        
        summary = f"Forecast generated by PatchTST model. Predicted mean load over the next {len(prediction)} steps: {probability:.2f}."
        signals = {"predicted_load_mean": probability, "predicted_load_series": prediction.tolist()}
        guidance = [f"Model predicts an average load of {probability:.2f}. Monitor system resources."]

        return ForecastResult(probability=probability, summary=summary, signals=signals, guidance=guidance)


    def risk_assessment(self, telemetry: Dict[str, dict]) -> ForecastResult:
        features = self._collect_features(telemetry)
        firewall_status = features["firewall"]
        process_anomalies = features["process"]
        backup_health = features["backup"]
        audit_signal = features["audit"]
        apps_success = features["apps"]

        alpha = 1.0
        beta = 1.0
        weighted_risks = [
            (1 - firewall_status, 5.0),
            (process_anomalies, 4.0),
            (1 - backup_health, 3.0),
            (1 - audit_signal, 3.0),
        ]
        for value, weight in weighted_risks:
            alpha += value * weight
            beta += (1 - value) * weight
        residual_risk = alpha / (alpha + beta)

        guidance = []
        if residual_risk > 0.7:
            guidance.append("Elevated security residual risk; recommend manual log review.")
        elif residual_risk > 0.4:
            guidance.append("Moderate residual risk; monitor anomalous processes.")
        else:
            guidance.append("Low residual risk based on current telemetry.")
        if apps_success < 0.5:
            guidance.append("Investigate failed supervised applications for security impact.")

        if self.forensic_mode:
            guidance.append("Ensure evidence retention remains immutable; avoid altering host artefacts.")

        summary = (
            "Security residual risk calculated from firewall posture, anomalous process ratios, backup health, audit events, and application success "
            f"evaluates to {residual_risk:.2%}."
        )

        signals = {
            "firewall_health": firewall_status,
            "process_anomaly_ratio": process_anomalies,
            "backup_health": backup_health,
            "audit_signal": audit_signal,
            "apps_success": apps_success,
        }
        return ForecastResult(probability=residual_risk, summary=summary, signals=signals, guidance=guidance)

    def quantum_projection(
        self,
        qubits: int = 10,
        telemetry: Optional[Dict[str, dict]] = None,
        seed: Optional[int] = None,
    ) -> QuantumResult:
        """
        Generates a quantum-enhanced projection using Hybrid Quantum MCMC.
        This method now performs Bayesian inference on key system parameters.
        """
        features = self._collect_features(telemetry or {})

        # Define a log-probability function based on system state.
        # This function represents our belief about a healthy system state.
        def log_prob_fn(params):
            # params[0] = load, params[1] = memory
            load_p, mem_p = params
            
            # Define a 'target' healthy state
            target_load = 0.3
            target_mem = 0.5
            
            # Use a Gaussian-like belief: probability is higher closer to the target state.
            logp = -((features["load"] - load_p)**2 / (2 * 0.1**2))
            logp += -((features["memory"] - mem_p)**2 / (2 * 0.1**2))
            return logp

        # Initialize and run the Hybrid Quantum MCMC sampler
        sampler = HybridQuantumMCMC(log_prob_fn=log_prob_fn, num_qubits=2)
        initial_state = np.array([features["load"], features["memory"]])
        posterior_samples = sampler.sample(initial_state, num_samples=500, burn_in=50)

        # The posterior samples represent the inferred distribution of 'healthy' load and memory
        # given the current state. We can analyze these samples.
        mean_load, mean_mem = np.mean(posterior_samples, axis=0)
        std_load, std_mem = np.std(posterior_samples, axis=0)
        
        # Entropy can be estimated from the variance of the posterior
        entropy = float(np.log(2 * np.pi * np.e * (std_load * std_mem))) / 2

        narrative = (
            f"Hybrid Quantum MCMC completed. Inferred system state:"
            f" Load={mean_load:.2f} (std={std_load:.2f}),"
            f" Memory={mean_mem:.2f} (std={std_mem:.2f})."
            f" System entropy estimated at {entropy:.2f}."
        )

        measurements = {
            "inferred_mean_load": mean_load,
            "inferred_std_load": std_load,
            "inferred_mean_memory": mean_mem,
            "inferred_std_memory": std_mem
        }

        return QuantumResult(qubits=2, measurements=measurements, entropy=entropy, narrative=narrative)

    def adaptive_guidance(self, forecast: ForecastResult, risk: ForecastResult, quantum: QuantumResult) -> List[str]:
        guidance = []
        if forecast.probability > 0.7 and risk.probability > 0.5:
            guidance.append("Synthesize cross-discipline response team; both operations and security show elevated signals.")
        if quantum.entropy < quantum.qubits / 2:
            guidance.append("Quantum projection indicates coherent state; predictions more deterministic.")
        else:
            guidance.append("Quantum projection entropy high; maintain probabilistic posture.")
        guidance.extend(forecast.guidance[:1])
        guidance.extend(risk.guidance[:1])
        return guidance

    # --- Internal signal extraction helpers -------------------------------------------------

    def _collect_features(self, telemetry: Dict[str, dict]) -> Dict[str, float]:
        return {
            "load": self._extract_load_signal(telemetry),
            "memory": self._extract_memory_signal(telemetry),
            "provider": self._extract_provider_health(telemetry),
            "container": self._extract_container_pressure(telemetry),
            "firewall": self._extract_firewall_health(telemetry),
            "process": self._extract_process_anomalies(telemetry),
            "backup": self._extract_backup_health(telemetry),
            "audit": self._extract_security_events(telemetry),
            "network": self._extract_network_reachability(telemetry),
            "dns": self._extract_dns_health(telemetry),
            "apps": self._extract_app_success(telemetry),
        }

    def _extract_load_signal(self, telemetry: Dict[str, dict]) -> float:
        load = telemetry.get("scalability.monitor_load", {})
        values = [
            load.get("load_1m", 0.0),
            load.get("load_5m", 0.0),
            load.get("load_15m", 0.0),
        ]
        cleaned = [v for v in values if isinstance(v, (int, float))]
        if not cleaned:
            return 0.3
        normalized = [min(1.5, max(0.0, v)) / 1.5 for v in cleaned]
        return sum(normalized) / len(normalized)

    def _extract_memory_signal(self, telemetry: Dict[str, dict]) -> float:
        kernel_mem = telemetry.get("kernel.memory_management", {})
        free_mb = kernel_mem.get("free_mb")
        total_mb = kernel_mem.get("total_mb") or kernel_mem.get("active_mb")
        if isinstance(free_mb, (int, float)) and isinstance(total_mb, (int, float)) and total_mb > 0:
            used_ratio = 1 - (free_mb / total_mb)
            return max(0.0, min(1.0, used_ratio))
        return 0.4

    def _extract_provider_health(self, telemetry: Dict[str, dict]) -> float:
        providers = telemetry.get("scalability.monitor_load", {}).get("providers", [])
        if not providers:
            return 0.5
        scores = []
        for provider in providers:
            healthy = provider.get("healthy")
            if healthy is True:
                scores.append(1.0)
            elif healthy is False:
                scores.append(0.0)
        if not scores:
            return 0.5
        return statistics.mean(scores)

    def _extract_container_pressure(self, telemetry: Dict[str, dict]) -> float:
        providers = telemetry.get("scalability.monitor_load", {}).get("providers", [])
        docker_stats = []
        for provider in providers:
            if provider.get("provider") == "docker":
                stats = provider.get("details", {}).get("stats") or []
                docker_stats.extend(stats)
        if not docker_stats:
            return 0.4
        pressures = []
        for entry in docker_stats:
            cpu = entry.get("CPUPerc") or entry.get("CPUPerc".lower())
            mem = entry.get("MemPerc") or entry.get("MemPerc".lower())
            cpu_value = self._parse_percentage(cpu)
            mem_value = self._parse_percentage(mem)
            if cpu_value is not None or mem_value is not None:
                combined = max(cpu_value or 0.0, mem_value or 0.0) / 100.0
                pressures.append(max(0.0, min(1.0, combined)))
        if not pressures:
            return 0.4
        return statistics.mean(pressures)

    def _extract_firewall_health(self, telemetry: Dict[str, dict]) -> float:
        firewall = telemetry.get("security.firewall", {})
        profiles = firewall.get("profiles")
        if isinstance(profiles, list) and profiles:
            enabled = [profile.get("Enabled") for profile in profiles if isinstance(profile, dict)]
            if enabled:
                ratio = sum(1 for flag in enabled if str(flag).lower() in {"true", "1"}) / len(enabled)
                return max(0.0, min(1.0, ratio))
        raw = firewall.get("raw")
        if isinstance(raw, str) and "State = 1" in raw:
            return 1.0
        return 0.6

    def _extract_process_anomalies(self, telemetry: Dict[str, dict]) -> float:
        scan = telemetry.get("security.threat_detection", {})
        anomalies = scan.get("high_cpu_candidates") or []
        sample = scan.get("sample") or []
        if sample:
            ratio = len(anomalies) / max(1, len(sample))
            return max(0.0, min(1.0, ratio))
        return 0.2

    def _extract_backup_health(self, telemetry: Dict[str, dict]) -> float:
        backup = telemetry.get("storage.backup", {})
        status = backup.get("status") or backup.get("status_code")
        if status and isinstance(status, str):
            if "error" in status.lower():
                return 0.2
            if "success" in status.lower():
                return 0.9
        return 0.5

    def _extract_security_events(self, telemetry: Dict[str, dict]) -> float:
        audit = telemetry.get("security.audit_review", {})
        events = audit.get("events") or audit.get("log_tail")
        if not events:
            return 0.6
        text = " ".join(str(event) for event in events)
        lowered = text.lower()
        if any(token in lowered for token in ["error", "fail", "denied", "critical"]):
            return 0.3
        return 0.8

    def _extract_network_reachability(self, telemetry: Dict[str, dict]) -> float:
        net = telemetry.get("networking.data_transmission", {})
        summary = net.get("ping_summary") or net.get("_message")
        if isinstance(summary, str):
            lowered = summary.lower()
            if any(term in lowered for term in ["ttl", "time=", "bytes"]):
                return 0.9
            if any(term in lowered for term in ["timeout", "unreachable", "host down"]):
                return 0.2
        return 0.5

    def _extract_dns_health(self, telemetry: Dict[str, dict]) -> float:
        resolver = telemetry.get("networking.dns_resolver", {})
        address = resolver.get("address")
        message = resolver.get("_message")
        if address:
            return 0.9
        if isinstance(message, str) and "error" in message.lower():
            return 0.3
        return 0.5

    def _extract_app_success(self, telemetry: Dict[str, dict]) -> float:
        supervisor = telemetry.get("application_supervisor", {})
        summary = supervisor.get("summary", {})
        total_specs = summary.get("total_specs") or 0
        if total_specs:
            completed = summary.get("completed") or 0
            failed = summary.get("failed") or 0
            errors = summary.get("errors") or 0
            success_ratio = max(0.0, min(1.0, completed / total_specs))
            penalty = max(0.0, min(1.0, (failed + errors) / total_specs))
            return max(0.0, min(1.0, success_ratio - penalty * 0.5))
        return 0.5

    def _parse_percentage(self, value: Optional[object]) -> Optional[float]:
        if value is None:
            return None
        if isinstance(value, (int, float)):
            return float(value)
        if isinstance(value, str):
            stripped = value.strip().strip("%")
            try:
                return float(stripped)
            except ValueError:
                return None
        return None


class QuantumCircuitSimulator:
    def __init__(self, qubits: int, seed: Optional[int] = None) -> None:
        self.qubits = qubits
        self.size = 1 << qubits
        self.state: List[complex] = [0j] * self.size
        self.state[0] = 1 + 0j
        self.rng = random.Random(seed)

    def apply_hadamard(self, qubit: int) -> None:
        step = 1 << qubit
        for block in range(0, self.size, step * 2):
            for offset in range(step):
                idx0 = block + offset
                idx1 = idx0 + step
                a = self.state[idx0]
                b = self.state[idx1]
                factor = 1 / math.sqrt(2)
                self.state[idx0] = (a + b) * factor
                self.state[idx1] = (a - b) * factor

    def apply_all_hadamard(self) -> None:
        for qubit in range(self.qubits):
            self.apply_hadamard(qubit)

    def apply_cnot(self, control: int, target: int) -> None:
        control_mask = 1 << control
        target_mask = 1 << target
        for idx in range(self.size):
            if idx & control_mask:
                partner = idx ^ target_mask
                if idx < partner:
                    self.state[idx], self.state[partner] = self.state[partner], self.state[idx]

    def apply_entanglement_chain(self) -> None:
        for ctrl in range(self.qubits - 1):
            self.apply_cnot(ctrl, ctrl + 1)

    def apply_phase(self, qubit: int, angle: float) -> None:
        phase = complex(math.cos(angle), math.sin(angle))
        mask = 1 << qubit
        for idx in range(self.size):
            if idx & mask:
                self.state[idx] *= phase

    def apply_feature_phases(self, features: Dict[str, float], forecast_hint: float, residual_hint: float) -> None:
        network_bias = features["network"]
        dns_bias = features["dns"]
        for qubit in range(self.qubits):
            angle = (
                (features["load"] * 0.25 + features["memory"] * 0.15) * (qubit + 1) / self.qubits
                + (network_bias + dns_bias) * 0.1 * (qubit + 1)
            ) * math.pi / 4
            self.apply_phase(qubit, angle)

        load_bias = forecast_hint - 0.5
        risk_bias = residual_hint - 0.5
        container_bias = features["container"] - 0.5
        for idx in range(self.size):
            pop = bin(idx).count("1")
            load_component = load_bias * (pop / max(1, self.qubits))
            risk_component = risk_bias * ((self.qubits - pop) / max(1, self.qubits))
            container_component = -container_bias * (pop / max(1, self.qubits)) * 0.5
            adjustment = 1 + load_component + risk_component + container_component
            if adjustment < 0:
                adjustment = 0
            self.state[idx] *= adjustment

        # Introduce small stochastic variation for diversity
        noise_scale = 0.02
        for idx in range(self.size):
            noise = (self.rng.random() - 0.5) * noise_scale
            self.state[idx] *= (1 + noise)

    def renormalize(self) -> None:
        norm = math.sqrt(sum((abs(amplitude) ** 2 for amplitude in self.state))) or 1.0
        self.state = [amplitude / norm for amplitude in self.state]

    def measure_distribution(self, max_states: int = 32) -> Dict[str, float]:
        probabilities = []
        for idx, amplitude in enumerate(self.state):
            probability = abs(amplitude) ** 2
            if probability > 0:
                probabilities.append((probability, idx))
        probabilities.sort(reverse=True)
        top = probabilities[: max_states]
        return {format(idx, f"0{self.qubits}b"): round(prob, 6) for prob, idx in top}

    def entropy(self) -> float:
        entropy = 0.0
        for amplitude in self.state:
            probability = abs(amplitude) ** 2
            if probability > 0:
                entropy -= probability * math.log2(probability)
        return entropy

    def _parse_percentage(self, value: Optional[object]) -> Optional[float]:
        if value is None:
            return None
        if isinstance(value, (int, float)):
            return float(value)
        if isinstance(value, str):
            stripped = value.strip().strip("%")
            try:
                return float(stripped)
            except ValueError:
                return None
        return None
